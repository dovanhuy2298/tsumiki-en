# TDD Test Case Identification

Identify test cases based on the requirements organized earlier.

## Preliminary Preparation

Prepare development context:

1. **Search for test-related information using @agent-symbol-searcher and read found files**

   - Search for existing test patterns and test cases, and read corresponding test files with Read tool
   - Identify testing methods and mock strategies for similar features, and read related files with Read tool
   - Check test framework usage and read configuration files with Read tool

2. **Direct reading of related files**
   - `docs/implements/{{task_id}}/{feature_name}-memo.md` - Check existing development history
   - `docs/implements/{{task_id}}/{feature_name}-requirements.md` - Check requirements definition
   - `docs/implements/{{task_id}}/{feature_name}-testcases.md` - Check existing test cases
   - Read related design documents and task files as needed

After loading completion, identify test cases based on prepared context information.

## Reliability Level Instructions

When creating each test case, always comment on the verification status with original materials (requirements definition, existing implementation, library documentation, etc.) using the following signals:

- ğŸŸ¢ **Green Signal**: When referring to original materials with minimal speculation
- ğŸŸ¡ **Yellow Signal**: When making reasonable speculation based on original materials
- ğŸ”´ **Red Signal**: When speculation is not based on original materials

## Test Case Classification

### 1. Normal System Test Cases (Basic Operations)

Please describe in the following format:

- **Test Name**: [Easy-to-understand Japanese name]
  - **What to Test**: [Specific operations or features to verify in this test]
  - **Expected Behavior**: [What processes should execute normally]
- **Input Values**: [Specific values]
  - **Meaning of Input Data**: [Why this input value was chosen, what it represents]
- **Expected Results**: [Specific expected values]
  - **Reason for Expected Results**: [Why this result is considered correct]
- **Test Purpose**: [What to verify]
  - **Verification Points**: [Points to pay special attention to during verification]
- ğŸŸ¢ğŸŸ¡ğŸ”´ State reliability level of this test case

### 2. Abnormal System Test Cases (Error Handling)

- **Test Name**: [Easy-to-understand Japanese name]
  - **Error Case Overview**: [What abnormal situation is anticipated]
  - **ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®é‡è¦æ€§**: [ãªãœã“ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒå¿…è¦ã‹]
- **å…¥åŠ›å€¤**: [ä¸æ­£ãªå€¤ã‚„å¢ƒç•Œã‚’è¶…ãˆãŸå€¤]
  - **ä¸æ­£ãªç†ç”±**: [ãªãœã“ã®å…¥åŠ›å€¤ãŒä¸æ­£ã¨ã•ã‚Œã‚‹ã‹]
  - **å®Ÿéš›ã®ç™ºç”Ÿã‚·ãƒŠãƒªã‚ª**: [å®Ÿé‹ç”¨ã§ã©ã®ã‚ˆã†ãªå ´é¢ã§ç™ºç”Ÿã™ã‚‹ã‹]
- **æœŸå¾…ã•ã‚Œã‚‹çµæœ**: [é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„ä¾‹å¤–]
  - **ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†…å®¹**: [ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦åˆ†ã‹ã‚Šã‚„ã™ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹]
  - **ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å…¨æ€§**: [ã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚·ã‚¹ãƒ†ãƒ ãŒå®‰å…¨ãªçŠ¶æ…‹ã‚’ä¿ã¦ã‚‹ã‹]
- **ãƒ†ã‚¹ãƒˆã®ç›®çš„**: [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ç¢ºèª]
  - **å“è³ªä¿è¨¼ã®è¦³ç‚¹**: [ã“ã®ãƒ†ã‚¹ãƒˆãŒã‚·ã‚¹ãƒ†ãƒ å“è³ªã«ã©ã†è²¢çŒ®ã™ã‚‹ã‹]
- ğŸŸ¢ğŸŸ¡ğŸ”´ ã“ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã‚’è¨˜è¼‰

### 3. å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ï¼ˆæœ€å°å€¤ã€æœ€å¤§å€¤ã€null ç­‰ï¼‰

- **ãƒ†ã‚¹ãƒˆå**: [ã‚ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªå]
  - **å¢ƒç•Œå€¤ã®æ„å‘³**: [ãªãœã“ã®å€¤ãŒå¢ƒç•Œã¨ã—ã¦é‡è¦ã‹]
  - **å¢ƒç•Œå€¤ã§ã®å‹•ä½œä¿è¨¼**: [å¢ƒç•Œä»˜è¿‘ã§ã®å‹•ä½œã®ä¸€è²«æ€§ç¢ºèª]
- **å…¥åŠ›å€¤**: [å¢ƒç•Œå€¤]
  - **å¢ƒç•Œå€¤é¸æŠã®æ ¹æ‹ **: [ãªãœã“ã®å€¤ã‚’å¢ƒç•Œå€¤ã¨ã—ã¦é¸ã‚“ã ã‹]
  - **å®Ÿéš›ã®ä½¿ç”¨å ´é¢**: [å®Ÿé‹ç”¨ã§ã“ã®å¢ƒç•Œå€¤ãŒã©ã†å½±éŸ¿ã™ã‚‹ã‹]
- **æœŸå¾…ã•ã‚Œã‚‹çµæœ**: [å¢ƒç•Œã§ã®å‹•ä½œ]
  - **å¢ƒç•Œã§ã®æ­£ç¢ºæ€§**: [å¢ƒç•Œå€¤ã§ã®è¨ˆç®—ã‚„å‡¦ç†ãŒæ­£ç¢ºã«è¡Œã‚ã‚Œã‚‹ã‹]
  - **ä¸€è²«ã—ãŸå‹•ä½œ**: [å¢ƒç•Œã®å†…å´ã¨å¤–å´ã§å‹•ä½œãŒä¸€è²«ã—ã¦ã„ã‚‹ã‹]
- **ãƒ†ã‚¹ãƒˆã®ç›®çš„**: [å¢ƒç•Œæ¡ä»¶ã®ç¢ºèª]
  - **å …ç‰¢æ€§ã®ç¢ºèª**: [ã‚·ã‚¹ãƒ†ãƒ ãŒæ¥µç«¯ãªæ¡ä»¶ä¸‹ã§ã‚‚å®‰å®šå‹•ä½œã™ã‚‹ã‹]
- ğŸŸ¢ğŸŸ¡ğŸ”´ ã“ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã‚’è¨˜è¼‰

## é–‹ç™ºè¨€èªãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

å®Ÿè£…ã«ä½¿ç”¨ã™ã‚‹è¨€èªãƒ»ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚‚ä½µã›ã¦æŒ‡å®šã—ã¦ãã ã•ã„ï¼š

- **ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª**: {{language}}
  - **è¨€èªé¸æŠã®ç†ç”±**: [ãªãœã“ã®è¨€èªã‚’é¸ã‚“ã ã‹]
  - **ãƒ†ã‚¹ãƒˆã«é©ã—ãŸæ©Ÿèƒ½**: [ã“ã®è¨€èªã®ãƒ†ã‚¹ãƒˆã«æœ‰åˆ©ãªç‰¹å¾´]
- **ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: {{test_framework}}
  - **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é¸æŠã®ç†ç”±**: [ãªãœã“ã®ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é¸ã‚“ã ã‹]
  - **ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç’°å¢ƒ**: [ã©ã®ã‚ˆã†ãªç’°å¢ƒã§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã‹]
- ğŸŸ¢ğŸŸ¡ğŸ”´ ã“ã®å†…å®¹ã®ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã‚’è¨˜è¼‰

## ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®Ÿè£…æ™‚ã®æ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆæŒ‡é‡

å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®å®Ÿè£…æ™‚ã«ã¯ä»¥ä¸‹ã®æ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ï¼š

### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹é–‹å§‹æ™‚ã®ã‚³ãƒ¡ãƒ³ãƒˆ

```javascript
// ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: [ã“ã®ãƒ†ã‚¹ãƒˆã§ä½•ã‚’ç¢ºèªã™ã‚‹ã‹ã‚’æ—¥æœ¬èªã§æ˜è¨˜]
// ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: [å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‹ã‚’èª¬æ˜]
// ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: [æ­£å¸¸ã«å‹•ä½œã—ãŸå ´åˆã®çµæœã‚’èª¬æ˜]
// ğŸŸ¢ğŸŸ¡ğŸ”´ ã“ã®å†…å®¹ã®ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã‚’è¨˜è¼‰
```

### Givenï¼ˆæº–å‚™ãƒ•ã‚§ãƒ¼ã‚ºï¼‰ã®ã‚³ãƒ¡ãƒ³ãƒˆ

```javascript
// ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™ã€‘: [ãªãœã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã™ã‚‹ã‹ã®ç†ç”±]
// ã€åˆæœŸæ¡ä»¶è¨­å®šã€‘: [ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå‰ã®çŠ¶æ…‹ã‚’èª¬æ˜]
// ã€å‰ææ¡ä»¶ç¢ºèªã€‘: [ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã«å¿…è¦ãªå‰ææ¡ä»¶ã‚’æ˜è¨˜]
```

### Whenï¼ˆå®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚ºï¼‰ã®ã‚³ãƒ¡ãƒ³ãƒˆ

```javascript
// ã€å®Ÿéš›ã®å‡¦ç†å®Ÿè¡Œã€‘: [ã©ã®æ©Ÿèƒ½/ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã™ã‹ã‚’èª¬æ˜]
// ã€å‡¦ç†å†…å®¹ã€‘: [å®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†ã®å†…å®¹ã‚’æ—¥æœ¬èªã§èª¬æ˜]
// ã€å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°ã€‘: [ãªãœã“ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å®Ÿè¡Œã™ã‚‹ã‹ã‚’èª¬æ˜]
```

### Thenï¼ˆæ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚ºï¼‰ã®ã‚³ãƒ¡ãƒ³ãƒˆ

```javascript
// ã€çµæœæ¤œè¨¼ã€‘: [ä½•ã‚’æ¤œè¨¼ã™ã‚‹ã‹ã‚’å…·ä½“çš„ã«èª¬æ˜]
// ã€æœŸå¾…å€¤ç¢ºèªã€‘: [æœŸå¾…ã•ã‚Œã‚‹çµæœã¨ãã®ç†ç”±ã‚’èª¬æ˜]
// ã€å“è³ªä¿è¨¼ã€‘: [ã“ã®æ¤œè¨¼ãŒã‚·ã‚¹ãƒ†ãƒ å“è³ªã«ã©ã†è²¢çŒ®ã™ã‚‹ã‹ã‚’èª¬æ˜]
```

### å„ expect ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®ã‚³ãƒ¡ãƒ³ãƒˆ

```javascript
// ã€æ¤œè¨¼é …ç›®ã€‘: [ã“ã®æ¤œè¨¼ã§ç¢ºèªã—ã¦ã„ã‚‹å…·ä½“çš„ãªé …ç›®]
// ğŸŸ¢ğŸŸ¡ğŸ”´ ã“ã®å†…å®¹ã®ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã‚’è¨˜è¼‰
expect(result.validPaths).toHaveLength(2); // ã€ç¢ºèªå†…å®¹ã€‘: æœ‰åŠ¹ãªãƒ‘ã‚¹ãŒæ­£ç¢ºã«2ã¤æ¤œå‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
expect(result.invalidPaths).toContain("nonexistent.json"); // ã€ç¢ºèªå†…å®¹ã€‘: å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ãƒ‘ã‚¹ã¨ã—ã¦é©åˆ‡ã«åˆ†é¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
```

### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®ã‚³ãƒ¡ãƒ³ãƒˆ

```javascript
beforeEach(() => {
  // ã€ãƒ†ã‚¹ãƒˆå‰æº–å‚™ã€‘: [å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå‰ã«è¡Œã†æº–å‚™ä½œæ¥­ã®èª¬æ˜]
  // ã€ç’°å¢ƒåˆæœŸåŒ–ã€‘: [ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ãªçŠ¶æ…‹ã«ã™ã‚‹ç†ç”±ã¨æ–¹æ³•]
});

afterEach(() => {
  // ã€ãƒ†ã‚¹ãƒˆå¾Œå‡¦ç†ã€‘: [å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå¾Œã«è¡Œã†ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä½œæ¥­ã®èª¬æ˜]
  // ã€çŠ¶æ…‹å¾©å…ƒã€‘: [æ¬¡ã®ãƒ†ã‚¹ãƒˆã«å½±éŸ¿ã—ãªã„ã‚ˆã†çŠ¶æ…‹ã‚’å¾©å…ƒã™ã‚‹ç†ç”±]
});
```

After identifying everything, execute the following:

1. Save test case list to docs/implements/{{task_id}}/{feature_name}-testcases.md (append if existing file exists)
2. Update TODO status (mark test case identification completion)
3. **Quality Assessment**: Assess test case quality based on the following criteria
   - Test case classification: Normal, abnormal, and boundary value cases are covered
   - Expected value definition: Expected values for each test case are clear
   - Technology selection: Programming language and test framework are determined
   - Implementation feasibility: Achievable with current technology stack
4. **Next Step Display**: Regardless of assessment results, display the next recommended command
   - "Next recommended step: Start Red phase (failing test creation) with `/tdd-red`."

## Quality Assessment Criteria

Assess test case quality based on the following criteria:

```
âœ… High Quality:
- Test case classification: Normal, abnormal, and boundary value cases are covered
- Expected value definition: Expected values for each test case are clear
- Technology selection: Programming language and test framework are determined
- Implementation feasibility: Achievable with current technology stack

âš ï¸ Needs Improvement:
- Test cases have gaps or duplicates
- Expected values are ambiguous or insufficient
- Technology selection is uncertain
- Too complex to implement

âŒ Inappropriate:
- Inconsistent with requirements
- Insufficient test cases
- Technical feasibility issues
```

## TODO Update Pattern

```
- Mark current TODO "Test case identification" as "completed"
- Reflect test case definition phase completion in TODO content
- Record quality assessment results in TODO content
- Add next phase "Red phase (failing test creation)" to TODO
```
